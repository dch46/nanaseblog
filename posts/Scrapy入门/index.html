<!DOCTYPE html>
<html><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="google" content="notranslate">
  <title>Scrapy入门 &middot; Nanase Blog</title>
  <meta name="keywords" content="书兰, inspiration, customization, rainmeter, design, web, 壁纸, 设计, 收集, wallpaper, collection, jaku, icon">
  <meta name="description" content="今日も頑張っていきましょ～">
  <meta name="author" content="Nanase">
  <link rel="icon" type="image/png" href="">
  <link rel="stylesheet" href="/css/diaspora.css">
  <link rel="stylesheet" href="/css/insight.css">
  <link rel="stylesheet" href="/css/custom.css">
</head><body class="loading">
        <div id="loading"></div>
				<div id="nav"></div>
				<div class="nav-user"></div>
    <div id="single">
    <div id="top" style="display: block;">
        <div class="bar">
        </div>
        <a class="icon-icon" href="javascript:history.back()">
        </a>
        <div title="播放/暂停" class="icon-play">
        </div>
        
        <h3 class="subtitle" style="display: none;">
        Scrapy入门</h3>
        <div class="social">
            <div>
                <div class="share">
                    <a title="获取二维码" class="icon-wechat" href="javascript:;"></a>
                </div>
                <div id="qr"></div>
            </div>
        </div>
        <div class="scrollbar" style="width: 1.1636%;"></div>
    </div>
    <div class="section">
        <div class="article">
            <div>
                <h1 class="title">
                Scrapy入门</h1>
                <div class="stuff">
                    
                    <span>August 25, 2017</span>
                    <span>字数 2470</span>
                    
                    
                </div>
                <div class="content">
                    <h2 id="scrapy爬虫框架入门">Scrapy爬虫框架入门</h2>
<h3 id="scrapy概述">Scrapy概述</h3>
<p>Scrapy是Python开发的一个非常流行的网络爬虫框架，可以用来抓取Web站点并从页面中提取结构化的数据，被广泛的用于数据挖掘、数据监测和自动化测试等领域。下图展示了Scrapy的基本架构，其中包含了主要组件和系统的数据处理流程（图中带数字的红色箭头）。</p>
<h4 id="组件">组件</h4>
<ol>
<li>Scrapy引擎（Engine）：Scrapy引擎是用来控制整个系统的数据处理流程。</li>
<li>调度器（Scheduler）：调度器从Scrapy引擎接受请求并排序列入队列，并在Scrapy引擎发出请求后返还给它们。</li>
<li>下载器（Downloader）：下载器的主要职责是抓取网页并将网页内容返还给蜘蛛（Spiders）。</li>
<li>蜘蛛（Spiders）：蜘蛛是有Scrapy用户自定义的用来解析网页并抓取特定URL返回的内容的类，每个蜘蛛都能处理一个域名或一组域名，简单的说就是用来定义特定网站的抓取和解析规则。</li>
<li>条目管道（Item Pipeline）：条目管道的主要责任是负责处理有蜘蛛从网页中抽取的数据条目，它的主要任务是清理、验证和存储数据。当页面被蜘蛛解析后，将被发送到条目管道，并经过几个特定的次序处理数据。每个条目管道组件都是一个Python类，它们获取了数据条目并执行对数据条目进行处理的方法，同时还需要确定是否需要在条目管道中继续执行下一步或是直接丢弃掉不处理。条目管道通常执行的任务有：清理HTML数据、验证解析到的数据（检查条目是否包含必要的字段）、检查是不是重复数据（如果重复就丢弃）、将解析到的数据存储到数据库（关系型数据库或NoSQL数据库）中。</li>
<li>中间件（Middlewares）：中间件是介于Scrapy引擎和其他组件之间的一个钩子框架，主要是为了提供自定义的代码来拓展Scrapy的功能，包括下载器中间件和蜘蛛中间件。</li>
</ol>
<h4 id="数据处理流程">数据处理流程</h4>
<p>Scrapy的整个数据处理流程由Scrapy引擎进行控制，通常的运转流程包括以下的步骤：</p>
<ol>
<li>
<p>引擎询问蜘蛛需要处理哪个网站，并让蜘蛛将第一个需要处理的URL交给它。</p>
</li>
<li>
<p>引擎让调度器将需要处理的URL放在队列中。</p>
</li>
<li>
<p>引擎从调度那获取接下来进行爬取的页面。</p>
</li>
<li>
<p>调度将下一个爬取的URL返回给引擎，引擎将它通过下载中间件发送到下载器。</p>
</li>
<li>
<p>当网页被下载器下载完成以后，响应内容通过下载中间件被发送到引擎；如果下载失败了，引擎会通知调度器记录这个URL，待会再重新下载。</p>
</li>
<li>
<p>引擎收到下载器的响应并将它通过蜘蛛中间件发送到蜘蛛进行处理。</p>
</li>
<li>
<p>蜘蛛处理响应并返回爬取到的数据条目，此外还要将需要跟进的新的URL发送给引擎。</p>
</li>
<li>
<p>引擎将抓取到的数据条目送入条目管道，把新的URL发送给调度器放入队列中。</p>
</li>
</ol>
<p>上述操作中的2-8步会一直重复直到调度器中没有需要请求的URL，爬虫停止工作。</p>
<h3 id="安装和使用scrapy">安装和使用Scrapy</h3>
<p>可以先创建虚拟环境并在虚拟环境下使用pip安装scrapy。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Shell" data-lang="Shell">
</code></pre></div><p>项目的目录结构如下图所示。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Shell" data-lang="Shell"><span style="color:#f92672">(</span>venv<span style="color:#f92672">)</span> $ tree
.
|____ scrapy.cfg
|____ douban
| |____ spiders
| | |____ __init__.py
| | |____ __pycache__
| |____ __init__.py
| |____ __pycache__
| |____ middlewares.py
| |____ settings.py
| |____ items.py
| |____ pipelines.py
</code></pre></div><blockquote>
<p>说明：Windows系统的命令行提示符下有tree命令，但是Linux和MacOS的终端是没有tree命令的，可以用下面给出的命令来定义tree命令，其实是对find命令进行了定制并别名为tree。</p>
<p><code>alias tree=&quot;find . -print | sed -e 's;[^/]*/;|____;g;s;____|; |;g'&quot;</code></p>
<p>Linux系统也可以通过yum或其他的包管理工具来安装tree。</p>
<p><code>yum install tree</code></p>
</blockquote>
<p>根据刚才描述的数据处理流程，基本上需要我们做的有以下几件事情：</p>
<ol>
<li>
<p>在items.py文件中定义字段，这些字段用来保存数据，方便后续的操作。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#75715e"># -*- coding: utf-8 -*-</span>
   
<span style="color:#75715e"># Define here the models for your scraped items</span>
<span style="color:#75715e">#</span>
<span style="color:#75715e"># See documentation in:</span>
<span style="color:#75715e"># https://doc.scrapy.org/en/latest/topics/items.html</span>
   
<span style="color:#f92672">import</span> scrapy
   
   
<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DoubanItem</span>(scrapy<span style="color:#f92672">.</span>Item):
   
    name <span style="color:#f92672">=</span> scrapy<span style="color:#f92672">.</span>Field()
    year <span style="color:#f92672">=</span> scrapy<span style="color:#f92672">.</span>Field()
    score <span style="color:#f92672">=</span> scrapy<span style="color:#f92672">.</span>Field()
    director <span style="color:#f92672">=</span> scrapy<span style="color:#f92672">.</span>Field()
    classification <span style="color:#f92672">=</span> scrapy<span style="color:#f92672">.</span>Field()
    actor <span style="color:#f92672">=</span> scrapy<span style="color:#f92672">.</span>Field()
</code></pre></div></li>
<li>
<p>在spiders文件夹中编写自己的爬虫。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Shell" data-lang="Shell"><span style="color:#f92672">(</span>venv<span style="color:#f92672">)</span> $ scrapy genspider movie movie.douban.com --template<span style="color:#f92672">=</span>crawl
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#75715e"># -*- coding: utf-8 -*-</span>
<span style="color:#f92672">import</span> scrapy
<span style="color:#f92672">from</span> scrapy.selector <span style="color:#f92672">import</span> Selector
<span style="color:#f92672">from</span> scrapy.linkextractors <span style="color:#f92672">import</span> LinkExtractor
<span style="color:#f92672">from</span> scrapy.spiders <span style="color:#f92672">import</span> CrawlSpider, Rule
   
<span style="color:#f92672">from</span> douban.items <span style="color:#f92672">import</span> DoubanItem
   
   
<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MovieSpider</span>(CrawlSpider):
    name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;movie&#39;</span>
    allowed_domains <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;movie.douban.com&#39;</span>]
    start_urls <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;https://movie.douban.com/top250&#39;</span>]
    rules <span style="color:#f92672">=</span> (
        Rule(LinkExtractor(allow<span style="color:#f92672">=</span>(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;https://movie.douban.com/top250\?start=\d+.*&#39;</span>))),
        Rule(LinkExtractor(allow<span style="color:#f92672">=</span>(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;https://movie.douban.com/subject/\d+&#39;</span>)), callback<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;parse_item&#39;</span>),
    )
   
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">parse_item</span>(self, response):
        sel <span style="color:#f92672">=</span> Selector(response)
        item <span style="color:#f92672">=</span> DoubanItem()
        item[<span style="color:#e6db74">&#39;name&#39;</span>]<span style="color:#f92672">=</span>sel<span style="color:#f92672">.</span>xpath(<span style="color:#e6db74">&#39;//*[@id=&#34;content&#34;]/h1/span[1]/text()&#39;</span>)<span style="color:#f92672">.</span>extract()
        item[<span style="color:#e6db74">&#39;year&#39;</span>]<span style="color:#f92672">=</span>sel<span style="color:#f92672">.</span>xpath(<span style="color:#e6db74">&#39;//*[@id=&#34;content&#34;]/h1/span[2]/text()&#39;</span>)<span style="color:#f92672">.</span>re(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\((\d+)\)&#39;</span>)
        item[<span style="color:#e6db74">&#39;score&#39;</span>]<span style="color:#f92672">=</span>sel<span style="color:#f92672">.</span>xpath(<span style="color:#e6db74">&#39;//*[@id=&#34;interest_sectl&#34;]/div/p[1]/strong/text()&#39;</span>)<span style="color:#f92672">.</span>extract()
        item[<span style="color:#e6db74">&#39;director&#39;</span>]<span style="color:#f92672">=</span>sel<span style="color:#f92672">.</span>xpath(<span style="color:#e6db74">&#39;//*[@id=&#34;info&#34;]/span[1]/a/text()&#39;</span>)<span style="color:#f92672">.</span>extract()
        item[<span style="color:#e6db74">&#39;classification&#39;</span>]<span style="color:#f92672">=</span> sel<span style="color:#f92672">.</span>xpath(<span style="color:#e6db74">&#39;//span[@property=&#34;v:genre&#34;]/text()&#39;</span>)<span style="color:#f92672">.</span>extract()
        item[<span style="color:#e6db74">&#39;actor&#39;</span>]<span style="color:#f92672">=</span> sel<span style="color:#f92672">.</span>xpath(<span style="color:#e6db74">&#39;//*[@id=&#34;info&#34;]/span[3]/a[1]/text()&#39;</span>)<span style="color:#f92672">.</span>extract()
        <span style="color:#66d9ef">return</span> item
</code></pre></div><blockquote>
<p>说明：上面我们通过Scrapy提供的爬虫模板创建了Spider，其中的rules中的LinkExtractor对象会自动完成对新的链接的解析，该对象中有一个名为extract_link的回调方法。Scrapy支持用XPath语法和CSS选择器进行数据解析，对应的方法分别是xpath和css，上面我们使用了XPath语法对页面进行解析，如果不熟悉XPath语法可以看看后面的补充说明。</p>
</blockquote>
<p>到这里，我们已经可以通过下面的命令让爬虫运转起来。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Shell" data-lang="Shell"><span style="color:#f92672">(</span>venv<span style="color:#f92672">)</span>$ scrapy crawl movie
</code></pre></div><p>可以在控制台看到爬取到的数据，如果想将这些数据保存到文件中，可以通过<code>-o</code>参数来指定文件名，Scrapy支持我们将爬取到的数据导出成JSON、CSV、XML、pickle、marshal等格式。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Shell" data-lang="Shell"><span style="color:#f92672">(</span>venv<span style="color:#f92672">)</span>$ scrapy crawl moive -o result.json
</code></pre></div></li>
<li>
<p>在pipelines.py中完成对数据进行持久化的操作。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#75715e"># -*- coding: utf-8 -*-</span>
   
<span style="color:#75715e"># Define your item pipelines here</span>
<span style="color:#75715e">#</span>
<span style="color:#75715e"># Don&#39;t forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span style="color:#75715e"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span style="color:#f92672">import</span> pymongo
   
<span style="color:#f92672">from</span> scrapy.exceptions <span style="color:#f92672">import</span> DropItem
<span style="color:#f92672">from</span> scrapy.conf <span style="color:#f92672">import</span> settings
<span style="color:#f92672">from</span> scrapy <span style="color:#f92672">import</span> log
   
   
<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DoubanPipeline</span>(object):
   
    <span style="color:#66d9ef">def</span> __init__(self):
        connection <span style="color:#f92672">=</span> pymongo<span style="color:#f92672">.</span>MongoClient(settings[<span style="color:#e6db74">&#39;MONGODB_SERVER&#39;</span>], settings[<span style="color:#e6db74">&#39;MONGODB_PORT&#39;</span>])
        db <span style="color:#f92672">=</span> connection[settings[<span style="color:#e6db74">&#39;MONGODB_DB&#39;</span>]]
        self<span style="color:#f92672">.</span>collection <span style="color:#f92672">=</span> db[settings[<span style="color:#e6db74">&#39;MONGODB_COLLECTION&#39;</span>]]
   
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">process_item</span>(self, item, spider):
        <span style="color:#75715e">#Remove invalid data</span>
        valid <span style="color:#f92672">=</span> True
        <span style="color:#66d9ef">for</span> data <span style="color:#f92672">in</span> item:
          <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> data:
            valid <span style="color:#f92672">=</span> False
            <span style="color:#66d9ef">raise</span> DropItem(<span style="color:#e6db74">&#34;Missing </span><span style="color:#e6db74">%s</span><span style="color:#e6db74"> of blogpost from </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span>(data, item[<span style="color:#e6db74">&#39;url&#39;</span>]))
        <span style="color:#66d9ef">if</span> valid:
        <span style="color:#75715e">#Insert data into database</span>
            new_moive<span style="color:#f92672">=</span>[{
                <span style="color:#e6db74">&#34;name&#34;</span>:item[<span style="color:#e6db74">&#39;name&#39;</span>][<span style="color:#ae81ff">0</span>],
                <span style="color:#e6db74">&#34;year&#34;</span>:item[<span style="color:#e6db74">&#39;year&#39;</span>][<span style="color:#ae81ff">0</span>],
                <span style="color:#e6db74">&#34;score&#34;</span>:item[<span style="color:#e6db74">&#39;score&#39;</span>],
                <span style="color:#e6db74">&#34;director&#34;</span>:item[<span style="color:#e6db74">&#39;director&#39;</span>],
                <span style="color:#e6db74">&#34;classification&#34;</span>:item[<span style="color:#e6db74">&#39;classification&#39;</span>],
                <span style="color:#e6db74">&#34;actor&#34;</span>:item[<span style="color:#e6db74">&#39;actor&#39;</span>]
            }]
            self<span style="color:#f92672">.</span>collection<span style="color:#f92672">.</span>insert(new_moive)
            log<span style="color:#f92672">.</span>msg(<span style="color:#e6db74">&#34;Item wrote to MongoDB database </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">/</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span>
            (settings[<span style="color:#e6db74">&#39;MONGODB_DB&#39;</span>], settings[<span style="color:#e6db74">&#39;MONGODB_COLLECTION&#39;</span>]),
            level<span style="color:#f92672">=</span>log<span style="color:#f92672">.</span>DEBUG, spider<span style="color:#f92672">=</span>spider) 
        <span style="color:#66d9ef">return</span> item
   
</code></pre></div><p>利用Pipeline我们可以完成以下操作：</p>
<ul>
<li>清理HTML数据，验证爬取的数据。</li>
<li>丢弃重复的不必要的内容。</li>
<li>将爬取的结果进行持久化操作。</li>
</ul>
</li>
<li>
<p>修改settings.py文件对项目进行配置。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#75715e"># -*- coding: utf-8 -*-</span>
   
<span style="color:#75715e"># Scrapy settings for douban project</span>
<span style="color:#75715e">#</span>
<span style="color:#75715e"># For simplicity, this file contains only settings considered important or</span>
<span style="color:#75715e"># commonly used. You can find more settings consulting the documentation:</span>
<span style="color:#75715e">#</span>
<span style="color:#75715e">#     https://doc.scrapy.org/en/latest/topics/settings.html</span>
<span style="color:#75715e">#     https://doc.scrapy.org/en/latest/topics/downloader-middleware.html</span>
<span style="color:#75715e">#     https://doc.scrapy.org/en/latest/topics/spider-middleware.html</span>
   
BOT_NAME <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;douban&#39;</span>
   
SPIDER_MODULES <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;douban.spiders&#39;</span>]
NEWSPIDER_MODULE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;douban.spiders&#39;</span>
   
   
<span style="color:#75715e"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span>
USER_AGENT <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.54 Safari/536.5&#39;</span>
   
<span style="color:#75715e"># Obey robots.txt rules</span>
ROBOTSTXT_OBEY <span style="color:#f92672">=</span> True
   
<span style="color:#75715e"># Configure maximum concurrent requests performed by Scrapy (default: 16)</span>
<span style="color:#75715e"># CONCURRENT_REQUESTS = 32</span>
   
<span style="color:#75715e"># Configure a delay for requests for the same website (default: 0)</span>
<span style="color:#75715e"># See https://doc.scrapy.org/en/latest/topics/settings.html#download-delay</span>
<span style="color:#75715e"># See also autothrottle settings and docs</span>
DOWNLOAD_DELAY <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
RANDOMIZE_DOWNLOAD_DELAY <span style="color:#f92672">=</span> True
<span style="color:#75715e"># The download delay setting will honor only one of:</span>
<span style="color:#75715e"># CONCURRENT_REQUESTS_PER_DOMAIN = 16</span>
<span style="color:#75715e"># CONCURRENT_REQUESTS_PER_IP = 16</span>
   
<span style="color:#75715e"># Disable cookies (enabled by default)</span>
COOKIES_ENABLED <span style="color:#f92672">=</span> True
   
MONGODB_SERVER <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;120.77.222.217&#39;</span>
MONGODB_PORT <span style="color:#f92672">=</span> <span style="color:#ae81ff">27017</span>
MONGODB_DB <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;douban&#39;</span>
MONGODB_COLLECTION <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;movie&#39;</span>
   
<span style="color:#75715e"># Disable Telnet Console (enabled by default)</span>
<span style="color:#75715e"># TELNETCONSOLE_ENABLED = False</span>
   
<span style="color:#75715e"># Override the default request headers:</span>
<span style="color:#75715e"># DEFAULT_REQUEST_HEADERS = {</span>
<span style="color:#75715e">#   &#39;Accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#39;,</span>
<span style="color:#75715e">#   &#39;Accept-Language&#39;: &#39;en&#39;,</span>
<span style="color:#75715e"># }</span>
   
<span style="color:#75715e"># Enable or disable spider middlewares</span>
<span style="color:#75715e"># See https://doc.scrapy.org/en/latest/topics/spider-middleware.html</span>
<span style="color:#75715e"># SPIDER_MIDDLEWARES = {</span>
<span style="color:#75715e">#    &#39;douban.middlewares.DoubanSpiderMiddleware&#39;: 543,</span>
<span style="color:#75715e"># }</span>
   
<span style="color:#75715e"># Enable or disable downloader middlewares</span>
<span style="color:#75715e"># See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html</span>
<span style="color:#75715e"># DOWNLOADER_MIDDLEWARES = {</span>
<span style="color:#75715e">#    &#39;douban.middlewares.DoubanDownloaderMiddleware&#39;: 543,</span>
<span style="color:#75715e"># }</span>
   
<span style="color:#75715e"># Enable or disable extensions</span>
<span style="color:#75715e"># See https://doc.scrapy.org/en/latest/topics/extensions.html</span>
<span style="color:#75715e"># EXTENSIONS = {</span>
<span style="color:#75715e">#    &#39;scrapy.extensions.telnet.TelnetConsole&#39;: None,</span>
<span style="color:#75715e"># }</span>
   
<span style="color:#75715e"># Configure item pipelines</span>
<span style="color:#75715e"># See https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
ITEM_PIPELINES <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#39;douban.pipelines.DoubanPipeline&#39;</span>: <span style="color:#ae81ff">400</span>,
}
   
LOG_LEVEL <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;DEBUG&#39;</span>
   
<span style="color:#75715e"># Enable and configure the AutoThrottle extension (disabled by default)</span>
<span style="color:#75715e"># See https://doc.scrapy.org/en/latest/topics/autothrottle.html</span>
<span style="color:#75715e">#AUTOTHROTTLE_ENABLED = True</span>
<span style="color:#75715e"># The initial download delay</span>
<span style="color:#75715e">#AUTOTHROTTLE_START_DELAY = 5</span>
<span style="color:#75715e"># The maximum download delay to be set in case of high latencies</span>
<span style="color:#75715e">#AUTOTHROTTLE_MAX_DELAY = 60</span>
<span style="color:#75715e"># The average number of requests Scrapy should be sending in parallel to</span>
<span style="color:#75715e"># each remote server</span>
<span style="color:#75715e">#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0</span>
<span style="color:#75715e"># Enable showing throttling stats for every response received:</span>
<span style="color:#75715e">#AUTOTHROTTLE_DEBUG = False</span>
   
<span style="color:#75715e"># Enable and configure HTTP caching (disabled by default)</span>
<span style="color:#75715e"># See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings</span>
HTTPCACHE_ENABLED <span style="color:#f92672">=</span> True
HTTPCACHE_EXPIRATION_SECS <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
HTTPCACHE_DIR <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;httpcache&#39;</span>
HTTPCACHE_IGNORE_HTTP_CODES <span style="color:#f92672">=</span> []
HTTPCACHE_STORAGE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;scrapy.extensions.httpcache.FilesystemCacheStorage&#39;</span>
</code></pre></div></li>
</ol>

                    
                    <audio id="audio" loop="1" preload="auto" style="width: 100%;" controls="controls" autoplay>
                        <source type="audio/mpeg" src="/mp3/%e3%82%b7%e3%83%b3%e3%82%af%e3%83%ad%e3%83%8b%e3%82%b7%e3%83%86%e3%82%a3.mp3">
                        <a href="/mp3/%e3%82%b7%e3%83%b3%e3%82%af%e3%83%ad%e3%83%8b%e3%82%b7%e3%83%86%e3%82%a3.mp3">/mp3/シンクロニシティ.mp3</a>
                    </audio>
                </div>
                <div class="comment-wrap">

                </div>
            </div>
        </div>
    </div>
    <div class="relate">
        <ul>
            <h3 id="prev_next">
                <em>相 关 文 章</em>
                <span>
                    <a href="javascript: window.scrollTo(0, 0);">
                    返回顶部</a>
                    
                        <a href="http://www.nishinonanase.xyz/posts/%E8%A7%A3%E6%9E%90%E5%8A%A8%E6%80%81%E5%86%85%E5%AE%B9/" rel="prev">上一篇</a>
                    
                    
                        <a href="http://www.nishinonanase.xyz/posts/%E5%B8%B8%E8%A7%81%E5%8F%8D%E7%88%AC%E7%AD%96%E7%95%A5%E5%8F%8A%E5%BA%94%E5%AF%B9%E6%96%B9%E6%A1%88/" rel="next">下一篇</a>
                    
                </span>
            </h3>
            
            
            
        </ul>
    </div>
</div>
<script>
    window.onload = function() {
        var audio = document.getElementById('audio');
        audio.play();
    }
</script>
<p style="text-align: center;">
  <a style="color: inherit" target="_blank" href="https://github.com/honjun/hugo-theme-diaspora"></a>
</p>

<script>
  var siteTitle = "Nanase Blog";
</script>
<script src="/js/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/diaspora.js"></script>
<script src="/js/custom.js"></script>
<script src="/js/InsightSearch.js"></script>
</body>
</html>

